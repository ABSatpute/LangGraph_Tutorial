{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf9ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aadcbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c431ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a732336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a state \n",
    "\n",
    "class LLMState(TypedDict):\n",
    "    \n",
    "    question: str\n",
    "    answer: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47226d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state: LLMState) -> LLMState: \n",
    "    \n",
    "    # extract the question from state\n",
    "    question = state['question']\n",
    "    \n",
    "    prompt = f'Answer the following question {question}'\n",
    "    \n",
    "    answer = model.invoke(prompt).content\n",
    "    \n",
    "    state['answer'] = answer\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c34b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our graph\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "#add nodes\n",
    "graph.add_node('llm_qa', llm_qa)\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START, 'llm_qa')\n",
    "graph.add_edge('llm_qa', END)\n",
    "\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44d5b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ha, Maharashtra madhe san asalyasathi puranpoli aani aamti bhat hindu satvik aharamadhye samavishth hou shakate. Puranpoli ek traditional Maharashtrian sweet dish ahe, ani aamti bhat ek healthy Maharashtrian meal ahe jyaat tandalachi aamti ani bhat hotat. Tyancha sevan karun manushya la arogya sathi upyogi asu shakate.\n"
     ]
    }
   ],
   "source": [
    "initial_state = {'question': 'Maharashtra madhe san aslyavar banavle janare puranpoli aani aamti bhat he hindu satvik aharamadhye samavishth hou shakate ka?'}\n",
    "final_state=workflow.invoke(initial_state)\n",
    "print(final_state['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c67eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
